{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"About","text":"<p>This site contains a collection of examples and inspiration for extending the users toolbox when writing unittests.</p> <p>While the examples are written in Python, the concepts are applicable to any language that supports unit testing.</p> <p>For people that are more into Python, some examples are implemented with both Pythons built in <code>unittest</code> framework as well as the third party <code>pytest</code> framework to show the differences and similarities between the two.</p>"},{"location":"index.html#a-common-definition-of-a-unit-test","title":"A common definition of a unit test","text":"<p>The definition of unit tests can vary depending on who you ask, which is why it is important to define what a unit test is in the context of this documentation.</p> <p>Here we've choosen to use the definition from Michael Feathers book Working Effectively with Legacy Code.</p> <p>In short, a test is not a unit test if:</p> <ol> <li>It talks to external resources (e.g. a database, the network, the file system, environment variables\u2026)</li> <li>It doesn\u2019t run fast ( &lt; 100ms/test)</li> </ol> <p>Info</p> <p>The book <code>Working Effectively with Legacy Code</code> is available at our office for borrowing.</p> <p>So from that definition we can conclude that a unit test does not need to be confined to single function or method, but can span multiple functions or methods as long as it does not talk to external resources and runs fast.</p> <p>Also please remember to always clean up after yourself, if you create a file, remove it, even if the test fails.</p> <p>We should be able to check out the repository, run the tests without any external resources and be sure that everything is cleaned up afterwards.</p>"},{"location":"index.html#table-of-contents","title":"Table of Contents","text":""},{"location":"index.html#before-starting","title":"Before Starting","text":"<ul> <li>Test Structure Methodology</li> <li>Package Specific Test Libraries</li> <li>Code Coverage</li> <li>Pytest Plugins</li> <li>Pytest CLI</li> </ul>"},{"location":"index.html#code-examples","title":"Code Examples","text":"<ul> <li>Assertion</li> <li>Mocking</li> <li>Fixtures</li> <li>Parametrization</li> <li>Markers</li> <li>Exceptions</li> <li>Capturing Output</li> <li>Logging</li> </ul>"},{"location":"assertion.html","title":"Assertion","text":""},{"location":"assertion.html#tests.test_assertion.TestAssertion","title":"<code>tests.test_assertion.TestAssertion</code>","text":"<p>Assertion is one of the fundamental concepts in testing, used to validate the expected result of a test. It is used to compare the actual result with the expected result. If the actual result matches the expected result, the test case passes; otherwise, it fails.</p>"},{"location":"assertion.html#tests.test_assertion.TestAssertion.test_assertion_pass","title":"<code>test_assertion_pass()</code>","text":"<p>In this test case, the assertion is True, so the test case passes.</p>          Source code in <code>tests/test_assertion.py</code> <pre><code>def test_assertion_pass(self):\n    \"\"\"\n    In this test case, the assertion is True, so the test case passes.\n    \"\"\"\n    assert 1 == 1\n</code></pre>"},{"location":"assertion.html#tests.test_assertion.TestAssertion.test_assertion_fail","title":"<code>test_assertion_fail()</code>","text":"<p>In this test case, the assertion is False, so the test case fails. The 'xfail' marker indicates that this test is expected to fail.</p>          Source code in <code>tests/test_assertion.py</code> <pre><code>@pytest.mark.xfail(reason=\"This test is expected to fail as a demonstration.\")\ndef test_assertion_fail(self):\n    \"\"\"\n    In this test case, the assertion is False, so the test case fails.\n    The 'xfail' marker indicates that this test is expected to fail.\n    \"\"\"\n    assert 1 == 2\n</code></pre>"},{"location":"assertion.html#tests.test_assertion.TestAssertion.test_assertion_with_message","title":"<code>test_assertion_with_message()</code>","text":"<p>You can also provide a message to the assertion to make it more informative. Note: The message is displayed only when the assertion fails.</p>          Source code in <code>tests/test_assertion.py</code> <pre><code>@pytest.mark.xfail(reason=\"This test is expected to fail as a demonstration.\")\ndef test_assertion_with_message(self):\n    \"\"\"\n    You can also provide a message to the assertion to make it more informative.\n    Note: The message is displayed only when the assertion fails.\n    \"\"\"\n    assert 1 == 2, \"1 is not equal to 2\"\n</code></pre>"},{"location":"assertion.html#tests.test_assertion.TestAssertion.test_list_equality","title":"<code>test_list_equality()</code>","text":"<p>This test checks if two lists are equal.</p>          Source code in <code>tests/test_assertion.py</code> <pre><code>def test_list_equality(self):\n    \"\"\"\n    This test checks if two lists are equal.\n    \"\"\"\n    list1 = [1, 2, 3]\n    list2 = [1, 2, 3]\n    assert list1 == list2, \"The two lists should be equal\"\n</code></pre>"},{"location":"assertion.html#tests.test_assertion.TestAssertion.test_string_contains","title":"<code>test_string_contains()</code>","text":"<p>This test checks if a string contains a substring.</p>          Source code in <code>tests/test_assertion.py</code> <pre><code>def test_string_contains(self):\n    \"\"\"\n    This test checks if a string contains a substring.\n    \"\"\"\n    string = \"Hello, world!\"\n    substring = \"world\"\n    assert substring in string, (\n        f\"The string should contain the substring '{substring}'\"\n    )\n</code></pre>"},{"location":"assertion.html#tests.test_assertion.TestAssertion.test_dict_key_presence","title":"<code>test_dict_key_presence()</code>","text":"<p>This test checks if a key is present in a dictionary.</p>          Source code in <code>tests/test_assertion.py</code> <pre><code>def test_dict_key_presence(self):\n    \"\"\"\n    This test checks if a key is present in a dictionary.\n    \"\"\"\n    my_dict = {\"key1\": \"value1\", \"key2\": \"value2\"}\n    assert \"key1\" in my_dict, \"The key 'key1' should be present in the dictionary\"\n</code></pre>"},{"location":"assertion.html#tests.test_assertion.TestAssertion.test_none_check","title":"<code>test_none_check()</code>","text":"<p>This test checks if a variable is None.</p>          Source code in <code>tests/test_assertion.py</code> <pre><code>def test_none_check(self):\n    \"\"\"\n    This test checks if a variable is None.\n    \"\"\"\n    var = None\n    assert var is None, \"The variable should be None\"\n</code></pre>"},{"location":"assertion.html#tests.test_assertion.TestAssertion.test_boolean_expression","title":"<code>test_boolean_expression()</code>","text":"<p>This test checks the truthiness of a boolean expression.</p>          Source code in <code>tests/test_assertion.py</code> <pre><code>def test_boolean_expression(self):\n    \"\"\"\n    This test checks the truthiness of a boolean expression.\n    \"\"\"\n    condition = 1 + 1 == 2\n    assert condition, \"The boolean expression should be True\"\n</code></pre>"},{"location":"assertion.html#tests.test_assertion.TestAssertion.test_approximate_equality","title":"<code>test_approximate_equality()</code>","text":"<p>This test checks if two floating-point numbers are approximately equal.</p>          Source code in <code>tests/test_assertion.py</code> <pre><code>def test_approximate_equality(self):\n    \"\"\"\n    This test checks if two floating-point numbers are approximately equal.\n    \"\"\"\n    num1 = 0.1 + 0.2\n    num2 = 0.3\n    assert num1 == pytest.approx(num2), (\n        \"The two numbers should be approximately equal\"\n    )\n</code></pre>"},{"location":"capturing-output.html","title":"Capturing Output","text":"<p>When testing code that writes to <code>stdout</code> or <code>stderr</code>, it is often useful to capture the output and check it in the test. This section will show you how to capture output from a function and how to assert that the output is as expected.</p>"},{"location":"capturing-output.html#tests.test_capturing_output.function_to_test","title":"<code>tests.test_capturing_output.function_to_test(print_argument)</code>","text":"<p>Function for demonstration purposes.</p> <p>This function prints the argument passed to it.</p>          Source code in <code>tests/test_capturing_output.py</code> <pre><code>def function_to_test(print_argument):\n    \"\"\"\n    Function for demonstration purposes.\n\n    This function prints the argument passed to it.\n    \"\"\"\n    print(print_argument)\n</code></pre>"},{"location":"capturing-output.html#tests.test_capturing_output.function_with_error","title":"<code>tests.test_capturing_output.function_with_error()</code>","text":"<p>Function for demonstration purposes.</p> <p>This function prints an error message to stderr.</p>          Source code in <code>tests/test_capturing_output.py</code> <pre><code>def function_with_error():\n    \"\"\"\n    Function for demonstration purposes.\n\n    This function prints an error message to stderr.\n    \"\"\"\n    import sys\n\n    print(\"This is an error message\", file=sys.stderr)\n</code></pre>"},{"location":"capturing-output.html#tests.test_capturing_output.TestCapturingOutput","title":"<code>tests.test_capturing_output.TestCapturingOutput</code>","text":"<p>This class demonstrates how to capture stdout and stderr using the capsys fixture from pytest.</p>"},{"location":"capturing-output.html#tests.test_capturing_output.TestCapturingOutput.test_capture_stdout","title":"<code>test_capture_stdout(capsys)</code>","text":"<p>This test captures the stdout output of function_to_test.</p>          Source code in <code>tests/test_capturing_output.py</code> <pre><code>def test_capture_stdout(self, capsys):\n    \"\"\"\n    This test captures the stdout output of function_to_test.\n    \"\"\"\n    function_to_test(\"Hello, World!\")\n    captured = capsys.readouterr()\n    assert captured.out == \"Hello, World!\\n\"\n    assert captured.err == \"\"\n</code></pre>"},{"location":"capturing-output.html#tests.test_capturing_output.TestCapturingOutput.test_capture_stderr","title":"<code>test_capture_stderr(capsys)</code>","text":"<p>This test captures the stderr output of function_with_error.</p>          Source code in <code>tests/test_capturing_output.py</code> <pre><code>def test_capture_stderr(self, capsys):\n    \"\"\"\n    This test captures the stderr output of function_with_error.\n    \"\"\"\n    function_with_error()\n    captured = capsys.readouterr()\n    assert captured.out == \"\"\n    assert captured.err == \"This is an error message\\n\"\n</code></pre>"},{"location":"capturing-output.html#tests.test_capturing_output.TestCapturingOutput.test_capture_both_stdout_and_stderr","title":"<code>test_capture_both_stdout_and_stderr(capsys)</code>","text":"<p>This test captures both stdout and stderr output.</p>          Source code in <code>tests/test_capturing_output.py</code> <pre><code>def test_capture_both_stdout_and_stderr(self, capsys):\n    \"\"\"\n    This test captures both stdout and stderr output.\n    \"\"\"\n    function_to_test(\"Output to stdout\")\n    function_with_error()\n    captured = capsys.readouterr()\n    assert captured.out == \"Output to stdout\\n\"\n    assert captured.err == \"This is an error message\\n\"\n</code></pre>"},{"location":"capturing-output.html#tests.test_capturing_output.TestCapturingOutput.test_partial_capture","title":"<code>test_partial_capture(capsys)</code>","text":"<p>This test demonstrates partially capturing output within a specific block of code.</p>          Source code in <code>tests/test_capturing_output.py</code> <pre><code>def test_partial_capture(self, capsys):\n    \"\"\"\n    This test demonstrates partially capturing output within a specific block of code.\n    \"\"\"\n    function_to_test(\"First message\")\n    with capsys.disabled():\n        print(\"This will not be captured by capsys\")\n    function_to_test(\"Second message\")\n\n    captured = capsys.readouterr()\n    assert captured.out == \"First message\\nSecond message\\n\"\n    assert captured.err == \"\"\n</code></pre>"},{"location":"capturing-output.html#tests.test_capturing_output.TestCapturingOutput.test_assert_no_output","title":"<code>test_assert_no_output(capsys)</code>","text":"<p>This test ensures there is no output captured when no functions are called.</p>          Source code in <code>tests/test_capturing_output.py</code> <pre><code>def test_assert_no_output(self, capsys):\n    \"\"\"\n    This test ensures there is no output captured when no functions are called.\n    \"\"\"\n    captured = capsys.readouterr()\n    assert captured.out == \"\"\n    assert captured.err == \"\"\n</code></pre>"},{"location":"code-coverage.html","title":"Coverage Reporting in Python","text":"<p>Code coverage is a measure used to describe the degree to which the source code of a program is tested by a particular test suite. <code>coverage.py</code> is a popular tool for measuring code coverage in Python projects.</p>"},{"location":"code-coverage.html#installation","title":"Installation","text":"<p>To get started with coverage reporting, you need to install <code>coverage.py</code>. Additionally, if you are using <code>pytest</code>, there is a plugin called <code>pytest-cov</code> that integrates coverage reporting with pytest.</p> <p>You can install these packages via pip:</p> <pre><code>pip install coverage pytest-cov\n</code></pre>"},{"location":"code-coverage.html#basic-usage-with-coveragepy","title":"Basic Usage with Coverage.py","text":""},{"location":"code-coverage.html#running-coverage-with-pytest","title":"Running Coverage with pytest","text":"<p>To run your tests with coverage using <code>pytest</code>, use the following command:</p> <pre><code>pytest --cov=myproject\n</code></pre> <p>In this command:</p> <ul> <li><code>--cov=myproject</code> specifies the module or package to measure for coverage.</li> </ul>"},{"location":"code-coverage.html#generating-the-report","title":"Generating the Report","text":"<p>After running your tests with coverage, you can generate a report. The most common reports are text, HTML, and XML reports.</p>"},{"location":"code-coverage.html#text-report","title":"Text Report","text":"<p>To generate a text report in the terminal:</p> <pre><code>pytest --cov=myproject --cov-report=term\n</code></pre>"},{"location":"code-coverage.html#html-report","title":"HTML Report","text":"<p>To generate an HTML report that you can view in a browser:</p> <pre><code>pytest --cov=myproject --cov-report=html\n</code></pre> <p>Open the generated <code>htmlcov/index.html</code> file in your web browser to view the report.</p>"},{"location":"code-coverage.html#xml-report","title":"XML Report","text":"<p>To generate an XML report, suitable for use with CI tools:</p> <pre><code>pytest --cov=myproject --cov-report=xml\n</code></pre>"},{"location":"code-coverage.html#integrating-with-pytest","title":"Integrating with pytest","text":""},{"location":"code-coverage.html#configuration","title":"Configuration","text":"<p>To simplify running tests with coverage using pytest, you can add configuration to your <code>pyproject.toml</code> file.</p>"},{"location":"code-coverage.html#pyprojecttoml","title":"pyproject.toml","text":"<p>Create or modify <code>pyproject.toml</code>:</p> <pre><code>[tool.pytest.ini_options]\naddopts = [\n    \"--cov=myproject\",\n    \"--cov-report=term\",\n    \"--cov-report=html\"\n]\n</code></pre> <p>In this configuration:</p> <ul> <li><code>--cov=myproject</code> specifies the module or package to measure for coverage.</li> <li><code>--cov-report=term</code> generates a text report in the terminal.</li> <li><code>--cov-report=html</code> generates an HTML report.</li> </ul>"},{"location":"code-coverage.html#running-tests-with-coverage","title":"Running Tests with Coverage","text":"<p>After configuration, simply run pytest to execute tests with coverage reporting:</p> <pre><code>pytest\n</code></pre>"},{"location":"code-coverage.html#ignoring-code-from-coverage","title":"Ignoring Code from Coverage","text":"<p>In some cases, you might want to exclude specific lines or files from the coverage report. You can use a special comment <code># pragma: no cover</code> to indicate that a line should not be considered when measuring coverage.</p>"},{"location":"code-coverage.html#ignoring-specific-lines","title":"Ignoring Specific Lines","text":"<pre><code># myproject/module.py\ndef add(a, b):\n    return a + b\n\ndef subtract(a, b):\n    return a - b\n\ndef multiply(a, b):  # pragma: no cover\n    return a * b\n</code></pre>"},{"location":"code-coverage.html#ignoring-entire-files","title":"Ignoring Entire Files","text":"<p>You can also configure <code>coverage.py</code> to omit entire files via the <code>pyproject.toml</code> configuration file.</p> <p>Create or modify <code>pyproject.toml</code> file:</p> <pre><code>[tool.coverage.run]\nomit = [\n    \"myproject/some_file_to_ignore.py\"\n]\n</code></pre>"},{"location":"code-coverage.html#integrating-with-azure-pipelines","title":"Integrating with Azure Pipelines","text":"<p>You can also integrate test coverage reporting into Azure Pipelines. Below is an example configuration for running tests with coverage and generating reports in an Azure Pipelines job.</p> <pre><code>jobs:\n  - job: \"test\"\n    displayName: \"Run tests\"\n    steps:\n      - checkout: self\n      - bash: |\n          curl -LsSf https://astral.sh/uv/install.sh | sh\n        displayName: \"Install uv\"\n      - bash: |\n          uv pip install pytest-azurepipelines\n          uv run pytest --cov=myproject --cov-report xml --cov-report html --junitxml junit/test-results.xml\n        displayName: \"Run tests\"\n      - task: reportgenerator@5\n        inputs:\n          reports: \"**/coverage.xml\"\n          targetdir: \"cover\"\n          publishCodeCoverageResults: true\n        displayName: \"Generate code coverage report\"\n</code></pre> <p>In this configuration:</p> <ul> <li>The <code>bash</code> step installs <code>uv</code>.</li> <li>The <code>bash</code> step runs <code>pytest</code> with coverage options, generating both XML and HTML reports.</li> <li>The <code>reportgenerator</code> task collects the coverage reports and uploads them to Azure Pipelines.</li> </ul>"},{"location":"code-coverage.html#conclusion","title":"Conclusion","text":"<p>Code coverage is an essential part of ensuring your tests adequately cover your codebase. Tools like <code>coverage.py</code> and <code>pytest-cov</code> make it easy to measure and report on code coverage. By integrating coverage reporting into your testing workflow, you can better understand which parts of your code are being tested and identify areas that may need additional tests.</p> <p>Integrating coverage reporting into CI tools like Azure Pipelines further enhances your development workflow by providing continuous feedback on your code coverage metrics.</p>"},{"location":"exceptions.html","title":"Exceptions","text":"<p>This section is about testing exception handling in Python. Maybe you want to test that a function raises an exception when it should, or maybe you want to test that a function does not raise an exception when it should not. This section will show you how to do both. It's also possible to assert certain properties of the exception that is raised, such as the exception message or the exception type.</p>"},{"location":"exceptions.html#tests.test_exceptions.function_that_raises","title":"<code>tests.test_exceptions.function_that_raises(value)</code>","text":"<p>A function for demonstrating exception handling in tests.</p> <p>This function raises a ValueError if the input is negative, a KeyError if the input is 0, and a CustomException if the input is 99.</p>          Source code in <code>tests/test_exceptions.py</code> <pre><code>def function_that_raises(value):\n    \"\"\"\n    A function for demonstrating exception handling in tests.\n\n    This function raises a ValueError if the input is negative, a KeyError if the input is 0, and a CustomException if the input is 99.\n    \"\"\"\n    if value &lt; 0:\n        raise ValueError(\"Negative value not allowed\")\n    elif value == 0:\n        raise KeyError(\"Value cannot be zero\")\n    elif value == 99:\n        raise CustomException(\"99 is a special case\")\n    else:\n        return value\n</code></pre>"},{"location":"exceptions.html#tests.test_exceptions.CustomException","title":"<code>tests.test_exceptions.CustomException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>A custom exception for demonstration purposes.</p>"},{"location":"exceptions.html#tests.test_exceptions.TestExceptionHandling","title":"<code>tests.test_exceptions.TestExceptionHandling</code>","text":"<p>This class demonstrates various ways to handle and test exceptions using pytest.</p>"},{"location":"exceptions.html#tests.test_exceptions.TestExceptionHandling.test_value_error","title":"<code>test_value_error()</code>","text":"<p>This test verifies that a ValueError is raised for negative input.</p>          Source code in <code>tests/test_exceptions.py</code> <pre><code>def test_value_error(self):\n    \"\"\"\n    This test verifies that a ValueError is raised for negative input.\n    \"\"\"\n    with pytest.raises(ValueError, match=\"Negative value not allowed\"):\n        function_that_raises(-1)\n</code></pre>"},{"location":"exceptions.html#tests.test_exceptions.TestExceptionHandling.test_key_error","title":"<code>test_key_error()</code>","text":"<p>This test verifies that a KeyError is raised for zero input.</p>          Source code in <code>tests/test_exceptions.py</code> <pre><code>def test_key_error(self):\n    \"\"\"\n    This test verifies that a KeyError is raised for zero input.\n    \"\"\"\n    with pytest.raises(KeyError, match=\"Value cannot be zero\"):\n        function_that_raises(0)\n</code></pre>"},{"location":"exceptions.html#tests.test_exceptions.TestExceptionHandling.test_custom_exception","title":"<code>test_custom_exception()</code>","text":"<p>This test verifies that a CustomException is raised for input 99.</p>          Source code in <code>tests/test_exceptions.py</code> <pre><code>def test_custom_exception(self):\n    \"\"\"\n    This test verifies that a CustomException is raised for input 99.\n    \"\"\"\n    with pytest.raises(CustomException, match=\"99 is a special case\"):\n        function_that_raises(99)\n</code></pre>"},{"location":"exceptions.html#tests.test_exceptions.TestExceptionHandling.test_multiple_exceptions","title":"<code>test_multiple_exceptions(input_value, expected_exception, expected_message)</code>","text":"<p>This test verifies multiple exception scenarios using parameterized inputs.</p>          Source code in <code>tests/test_exceptions.py</code> <pre><code>@pytest.mark.parametrize(\n    \"input_value, expected_exception, expected_message\",\n    [\n        (-1, ValueError, \"Negative value not allowed\"),\n        (0, KeyError, \"Value cannot be zero\"),\n        (99, CustomException, \"99 is a special case\"),\n    ],\n)\ndef test_multiple_exceptions(\n    self, input_value, expected_exception, expected_message\n):\n    \"\"\"\n    This test verifies multiple exception scenarios using parameterized inputs.\n    \"\"\"\n    with pytest.raises(expected_exception, match=expected_message):\n        function_that_raises(input_value)\n</code></pre>"},{"location":"exceptions.html#tests.test_exceptions.TestExceptionHandling.test_no_exception","title":"<code>test_no_exception()</code>","text":"<p>This test verifies that no exception is raised for positive input except 99.</p>          Source code in <code>tests/test_exceptions.py</code> <pre><code>def test_no_exception(self):\n    \"\"\"\n    This test verifies that no exception is raised for positive input except 99.\n    \"\"\"\n    assert function_that_raises(1) == 1\n    assert function_that_raises(50) == 50\n</code></pre>"},{"location":"exceptions.html#tests.test_exceptions.TestExceptionHandling.test_inspecting_exception","title":"<code>test_inspecting_exception()</code>","text":"<p>This test inspects the attributes of a raised exception.</p>          Source code in <code>tests/test_exceptions.py</code> <pre><code>def test_inspecting_exception(self):\n    \"\"\"\n    This test inspects the attributes of a raised exception.\n    \"\"\"\n    with pytest.raises(ValueError) as excinfo:\n        function_that_raises(-1)\n    assert excinfo.type is ValueError\n    assert excinfo.value.args[0] == \"Negative value not allowed\"\n</code></pre>"},{"location":"fixtures.html","title":"Fixtures","text":""},{"location":"fixtures.html#tests.test_fixtures.TestFixtures","title":"<code>tests.test_fixtures.TestFixtures</code>","text":"<p>Fixtures in Pytest provide a way to initialize resources and to provide these resources to the test functions.</p> <p>It's a great way to define reusable data or setup code that can be used across multiple tests.</p> <p>Note</p> <p>Fixtures usually does not go into a class, but for demonstration purposes, we are using a class here to group the fixtures together.</p>"},{"location":"fixtures.html#tests.test_fixtures.TestFixtures.simple_data","title":"<code>simple_data()</code>","text":"<p>This fixture provides a simple dataset for testing purposes.</p>          Source code in <code>tests/test_fixtures.py</code> <pre><code>@pytest.fixture\ndef simple_data(self):\n    \"\"\"\n    This fixture provides a simple dataset for testing purposes.\n    \"\"\"\n    return {\"key\": \"value\", \"number\": 42}\n</code></pre>"},{"location":"fixtures.html#tests.test_fixtures.TestFixtures.complex_data","title":"<code>complex_data()</code>","text":"<p>This fixture provides a more complex dataset.</p>          Source code in <code>tests/test_fixtures.py</code> <pre><code>@pytest.fixture\ndef complex_data(self):\n    \"\"\"\n    This fixture provides a more complex dataset.\n    \"\"\"\n    data = {\n        \"users\": [\n            {\"id\": 1, \"name\": \"Alice\"},\n            {\"id\": 2, \"name\": \"Bob\"},\n        ],\n        \"settings\": {\"theme\": \"dark\", \"notifications\": True},\n    }\n    return data\n</code></pre>"},{"location":"fixtures.html#tests.test_fixtures.TestFixtures.database_connection","title":"<code>database_connection()</code>","text":"<p>This fixture mocks a database connection. It is set to module scope so it will be setup once per module and shared between tests.</p>          Source code in <code>tests/test_fixtures.py</code> <pre><code>@pytest.fixture(scope=\"module\")\ndef database_connection(self):\n    \"\"\"\n    This fixture mocks a database connection. It is set to module\n    scope so it will be setup once per module and shared between tests.\n    \"\"\"\n    connection = \"database_connection\"\n    yield connection\n    # Tear down\n    connection = None\n    print(\"Closed database connection\")\n</code></pre>"},{"location":"fixtures.html#tests.test_fixtures.TestFixtures.app_config","title":"<code>app_config()</code>","text":"<p>This fixture provides application configuration. It is set to session scope so it will be setup once per test session.</p>          Source code in <code>tests/test_fixtures.py</code> <pre><code>@pytest.fixture(scope=\"session\")\ndef app_config(self):\n    \"\"\"\n    This fixture provides application configuration.\n    It is set to session scope so it will be setup once per test session.\n    \"\"\"\n    config = {\"version\": \"1.0.0\", \"name\": \"Sample Application\"}\n    yield config\n</code></pre>"},{"location":"fixtures.html#tests.test_fixtures.TestFixtures.temp_file","title":"<code>temp_file(tmp_path)</code>","text":"<p>This fixture creates a temporary file for testing.</p>          Source code in <code>tests/test_fixtures.py</code> <pre><code>@pytest.fixture\ndef temp_file(self, tmp_path):\n    \"\"\"\n    This fixture creates a temporary file for testing.\n    \"\"\"\n    file = tmp_path / \"temp_file.txt\"\n    file.write_text(\"Temporary file content\")\n    return file\n</code></pre>"},{"location":"fixtures.html#tests.test_fixtures.TestFixtures.mock_environment_variable","title":"<code>mock_environment_variable(monkeypatch)</code>","text":"<p>This fixture mocks an environment variable using the monkeypatch plugin from pytest.</p>          Source code in <code>tests/test_fixtures.py</code> <pre><code>@pytest.fixture\ndef mock_environment_variable(self, monkeypatch):\n    \"\"\"\n    This fixture mocks an environment variable using the monkeypatch plugin from pytest.\n    \"\"\"\n    monkeypatch.setenv(\"ENV_VAR\", \"mocked_value\")\n    yield\n    monkeypatch.undo()\n</code></pre>"},{"location":"fixtures.html#tests.test_fixtures.TestUsingFixtures","title":"<code>tests.test_fixtures.TestUsingFixtures</code>","text":"<p>               Bases: <code>TestFixtures</code></p> <p>This class demonstrates the usage of the fixtures defined in the TestFixtures class.</p>"},{"location":"fixtures.html#tests.test_fixtures.TestUsingFixtures.test_simple_data_fixture","title":"<code>test_simple_data_fixture(simple_data)</code>","text":"<p>This test uses the simple_data fixture.</p>          Source code in <code>tests/test_fixtures.py</code> <pre><code>def test_simple_data_fixture(self, simple_data):\n    \"\"\"\n    This test uses the simple_data fixture.\n    \"\"\"\n    assert simple_data[\"key\"] == \"value\"\n    assert simple_data[\"number\"] == 42\n</code></pre>"},{"location":"fixtures.html#tests.test_fixtures.TestUsingFixtures.test_complex_data_fixture","title":"<code>test_complex_data_fixture(complex_data)</code>","text":"<p>This test uses the complex_data fixture.</p>          Source code in <code>tests/test_fixtures.py</code> <pre><code>def test_complex_data_fixture(self, complex_data):\n    \"\"\"\n    This test uses the complex_data fixture.\n    \"\"\"\n    users = complex_data[\"users\"]\n    assert isinstance(users, list)\n    assert len(users) == 2\n    assert users[0][\"name\"] == \"Alice\"\n    assert complex_data[\"settings\"][\"theme\"] == \"dark\"\n</code></pre>"},{"location":"fixtures.html#tests.test_fixtures.TestUsingFixtures.test_database_connection_fixture","title":"<code>test_database_connection_fixture(database_connection)</code>","text":"<p>This test uses the database_connection fixture.</p>          Source code in <code>tests/test_fixtures.py</code> <pre><code>def test_database_connection_fixture(self, database_connection):\n    \"\"\"\n    This test uses the database_connection fixture.\n    \"\"\"\n    assert database_connection == \"database_connection\"\n</code></pre>"},{"location":"fixtures.html#tests.test_fixtures.TestUsingFixtures.test_app_config_fixture","title":"<code>test_app_config_fixture(app_config)</code>","text":"<p>This test uses the app_config fixture.</p>          Source code in <code>tests/test_fixtures.py</code> <pre><code>def test_app_config_fixture(self, app_config):\n    \"\"\"\n    This test uses the app_config fixture.\n    \"\"\"\n    assert app_config[\"version\"] == \"1.0.0\"\n    assert app_config[\"name\"] == \"Sample Application\"\n</code></pre>"},{"location":"fixtures.html#tests.test_fixtures.TestUsingFixtures.test_temp_file_fixture","title":"<code>test_temp_file_fixture(temp_file)</code>","text":"<p>This test uses the temp_file fixture.</p>          Source code in <code>tests/test_fixtures.py</code> <pre><code>def test_temp_file_fixture(self, temp_file):\n    \"\"\"\n    This test uses the temp_file fixture.\n    \"\"\"\n    assert temp_file.read_text() == \"Temporary file content\"\n</code></pre>"},{"location":"fixtures.html#tests.test_fixtures.TestUsingFixtures.test_mock_environment_variable_fixture","title":"<code>test_mock_environment_variable_fixture(mock_environment_variable)</code>","text":"<p>This test uses the mock_environment_variable fixture.</p>          Source code in <code>tests/test_fixtures.py</code> <pre><code>def test_mock_environment_variable_fixture(self, mock_environment_variable):\n    \"\"\"\n    This test uses the mock_environment_variable fixture.\n    \"\"\"\n    import os\n\n    assert os.getenv(\"ENV_VAR\") == \"mocked_value\"\n</code></pre>"},{"location":"fixtures.html#tests.test_fixtures.TestUsingFixtures.test_combined_fixtures","title":"<code>test_combined_fixtures(simple_data, complex_data, app_config)</code>","text":"<p>This test uses multiple fixtures to verify combined use.</p>          Source code in <code>tests/test_fixtures.py</code> <pre><code>def test_combined_fixtures(self, simple_data, complex_data, app_config):\n    \"\"\"\n    This test uses multiple fixtures to verify combined use.\n    \"\"\"\n    assert simple_data[\"key\"] == \"value\"\n    assert len(complex_data[\"users\"]) == 2\n    assert app_config[\"version\"] == \"1.0.0\"\n</code></pre>"},{"location":"logging.html","title":"Logging","text":"<p>Logging is always useful, it can help you understand what your code is doing and why it is doing it. This chapter is divided into two sections: logging during testing and capturing log messages during testing.</p> <p>Info</p> <p>The following section covers using log messages during testing.</p> <p>Info</p> <p>The following section covers capturing log messages during testing.</p>"},{"location":"logging.html#tests.test_logging.log_start_and_end","title":"<code>tests.test_logging.log_start_and_end(request)</code>","text":"<p>Fixture for demonstration purposes of TestLoggingDuringTests.</p> <p>Fixture to log the start and end of each test.</p>          Source code in <code>tests/test_logging.py</code> <pre><code>@pytest.fixture(scope=\"function\")\ndef log_start_and_end(request):\n    \"\"\"\n    Fixture for demonstration purposes of TestLoggingDuringTests.\n\n    Fixture to log the start and end of each test.\n    \"\"\"\n    logger.info(f\"Starting test: {request.node.name}\")\n    yield\n    logger.info(f\"Finished test: {request.node.name}\")\n</code></pre>"},{"location":"logging.html#tests.test_logging.TestLoggingDuringTests","title":"<code>tests.test_logging.TestLoggingDuringTests</code>","text":"<p>Class to demonstrate logging within multiple tests in a class.</p>"},{"location":"logging.html#tests.test_logging.TestLoggingDuringTests.test_addition","title":"<code>test_addition()</code>","text":"<p>Test to demonstrate logging within tests. This test checks the addition operation.</p>          Source code in <code>tests/test_logging.py</code> <pre><code>def test_addition(self):\n    \"\"\"\n    Test to demonstrate logging within tests. This test checks the addition operation.\n    \"\"\"\n    logger.info(\"Starting test_addition\")\n    a = 2\n    b = 3\n    logger.debug(f\"Values: a={a}, b={b}\")\n    result = a + b\n    logger.debug(f\"Result: {result}\")\n    logger.info(\"Asserting the result\")\n    assert result == 5\n    logger.info(\"Finished test_addition\")\n</code></pre>"},{"location":"logging.html#tests.test_logging.TestLoggingDuringTests.test_subtraction","title":"<code>test_subtraction()</code>","text":"<p>Test to demonstrate logging within tests. This test checks the subtraction operation.</p>          Source code in <code>tests/test_logging.py</code> <pre><code>def test_subtraction(self):\n    \"\"\"\n    Test to demonstrate logging within tests. This test checks the subtraction operation.\n    \"\"\"\n    logger.info(\"Starting test_subtraction\")\n    a = 10\n    b = 5\n    logger.debug(f\"Values: a={a}, b={b}\")\n    result = a - b\n    logger.debug(f\"Result: {result}\")\n    logger.info(\"Asserting the result\")\n    assert result == 5\n    logger.info(\"Finished test_subtraction\")\n</code></pre>"},{"location":"logging.html#tests.test_logging.TestLoggingDuringTests.test_multiplication","title":"<code>test_multiplication()</code>","text":"<p>Test to check the multiplication operation.</p>          Source code in <code>tests/test_logging.py</code> <pre><code>def test_multiplication(self):\n    \"\"\"\n    Test to check the multiplication operation.\n    \"\"\"\n    logger.info(\"Starting test_multiplication\")\n    a = 3\n    b = 4\n    logger.debug(f\"Values: a={a}, b={b}\")\n    result = a * b\n    logger.debug(f\"Result: {result}\")\n    logger.info(\"Asserting the result\")\n    assert result == 12\n    logger.info(\"Finished test_multiplication\")\n</code></pre>"},{"location":"logging.html#tests.test_logging.TestLoggingDuringTests.test_division","title":"<code>test_division()</code>","text":"<p>Test to check the division operation and handle division by zero.</p>          Source code in <code>tests/test_logging.py</code> <pre><code>def test_division(self):\n    \"\"\"\n    Test to check the division operation and handle division by zero.\n    \"\"\"\n    logger.info(\"Starting test_division\")\n    a = 8\n    b = 2\n    logger.debug(f\"Values: a={a}, b={b}\")\n    try:\n        result = a / b\n        logger.debug(f\"Result: {result}\")\n        logger.info(\"Asserting the result\")\n        assert result == 4\n    except ZeroDivisionError as e:\n        logger.error(\"Caught division by zero exception\", exc_info=True)\n        pytest.fail(\"Division by zero\")\n    logger.info(\"Finished test_division\")\n</code></pre>"},{"location":"logging.html#tests.test_logging.TestLoggingDuringTests.test_division_by_zero","title":"<code>test_division_by_zero()</code>","text":"<p>Test to check division by zero operation.</p>          Source code in <code>tests/test_logging.py</code> <pre><code>def test_division_by_zero(self):\n    \"\"\"\n    Test to check division by zero operation.\n    \"\"\"\n    logger.info(\"Starting test_division_by_zero\")\n    a = 8\n    b = 0\n    logger.debug(f\"Values: a={a}, b={b}\")\n    with pytest.raises(ZeroDivisionError):\n        result = a / b\n    logger.info(\"Finished test_division_by_zero\")\n</code></pre>"},{"location":"logging.html#tests.test_logging.function_to_log","title":"<code>tests.test_logging.function_to_log()</code>","text":"<p>Function for demonstration purposes of TestLoggingCapture.</p> <p>This function logs messages at different severity levels.</p>          Source code in <code>tests/test_logging.py</code> <pre><code>def function_to_log():\n    \"\"\"\n    Function for demonstration purposes of TestLoggingCapture.\n\n    This function logs messages at different severity levels.\n    \"\"\"\n    logger.debug(\"Debug message\")\n    logger.info(\"Information message\")\n    logger.warning(\"Warning message\")\n    logger.error(\"Error message\")\n    logger.critical(\"Critical message\")\n</code></pre>"},{"location":"logging.html#tests.test_logging.custom_log_function","title":"<code>tests.test_logging.custom_log_function()</code>","text":"<p>Function for demonstration purposes of TestLoggingCapture.</p> <p>This function logs a custom message.</p>          Source code in <code>tests/test_logging.py</code> <pre><code>def custom_log_function():\n    \"\"\"\n    Function for demonstration purposes of TestLoggingCapture.\n\n    This function logs a custom message.\n    \"\"\"\n    logger.info(\"This is a custom log message\")\n</code></pre>"},{"location":"logging.html#tests.test_logging.check_log_contains","title":"<code>tests.test_logging.check_log_contains(caplog, level, message)</code>","text":"<p>Function for demonstration purposes of TestLoggingCapture.</p> <p>Helper function to assert that a specific log message at a given level is captured.</p>          Source code in <code>tests/test_logging.py</code> <pre><code>def check_log_contains(caplog, level, message):\n    \"\"\"\n    Function for demonstration purposes of TestLoggingCapture.\n\n    Helper function to assert that a specific log message at a given level is captured.\n    \"\"\"\n    assert any(\n        record.levelno == level and message in record.message\n        for record in caplog.records\n    )\n</code></pre>"},{"location":"logging.html#tests.test_logging.TestLoggingCapture","title":"<code>tests.test_logging.TestLoggingCapture</code>","text":"<p>This class demonstrates how to capture and test logging output using pytest.</p>"},{"location":"logging.html#tests.test_logging.TestLoggingCapture.test_capture_log_output","title":"<code>test_capture_log_output(caplog)</code>","text":"<p>This test captures log output and verifies it contains the expected messages.</p>          Source code in <code>tests/test_logging.py</code> <pre><code>def test_capture_log_output(self, caplog):\n    \"\"\"\n    This test captures log output and verifies it contains the expected messages.\n    \"\"\"\n    with caplog.at_level(logging.DEBUG):\n        function_to_log()\n\n    # Caplog records the log messages and their levels\n    assert \"Debug message\" in caplog.text\n    assert \"Information message\" in caplog.text\n    assert \"Warning message\" in caplog.text\n    assert \"Error message\" in caplog.text\n    assert \"Critical message\" in caplog.text\n\n    # Optional: Verify the log level for each message\n    assert any(record.levelno == logging.DEBUG for record in caplog.records)\n    assert any(record.levelno == logging.INFO for record in caplog.records)\n    assert any(record.levelno == logging.WARNING for record in caplog.records)\n    assert any(record.levelno == logging.ERROR for record in caplog.records)\n    assert any(record.levelno == logging.CRITICAL for record in caplog.records)\n</code></pre>"},{"location":"logging.html#tests.test_logging.TestLoggingCapture.test_custom_log_message","title":"<code>test_custom_log_message(caplog)</code>","text":"<p>This test captures a custom log message and verifies its content.</p>          Source code in <code>tests/test_logging.py</code> <pre><code>def test_custom_log_message(self, caplog):\n    \"\"\"\n    This test captures a custom log message and verifies its content.\n    \"\"\"\n    with caplog.at_level(logging.INFO):\n        custom_log_function()\n\n    assert \"This is a custom log message\" in caplog.text\n\n    # Optionally, check that the message is logged at the expected level\n    assert any(record.levelno == logging.INFO for record in caplog.records)\n</code></pre>"},{"location":"logging.html#tests.test_logging.TestLoggingCapture.test_no_logs_at_lower_level","title":"<code>test_no_logs_at_lower_level(caplog)</code>","text":"<p>This test ensures no logs are captured below a specific level.</p>          Source code in <code>tests/test_logging.py</code> <pre><code>def test_no_logs_at_lower_level(self, caplog):\n    \"\"\"\n    This test ensures no logs are captured below a specific level.\n    \"\"\"\n    with caplog.at_level(logging.WARNING):\n        custom_log_function()\n\n    # Since the logging level is set to WARNING, the INFO log should not appear\n    assert \"This is a custom log message\" not in caplog.text\n</code></pre>"},{"location":"logging.html#tests.test_logging.TestLoggingCapture.test_clear_logs","title":"<code>test_clear_logs(caplog)</code>","text":"<p>This test demonstrates how to clear captured logs between tests or check points.</p>          Source code in <code>tests/test_logging.py</code> <pre><code>def test_clear_logs(self, caplog):\n    \"\"\"\n    This test demonstrates how to clear captured logs between tests or check points.\n    \"\"\"\n    with caplog.at_level(logging.INFO):\n        custom_log_function()\n\n    assert \"This is a custom log message\" in caplog.text\n\n    # Clear the captured logs\n    caplog.clear()\n\n    assert \"This is a custom log message\" not in caplog.text\n</code></pre>"},{"location":"logging.html#tests.test_logging.TestLoggingCapture.test_assert_log_contains","title":"<code>test_assert_log_contains(caplog)</code>","text":"<p>This test demonstrates a helper function to assert that a specific log message is captured.</p>          Source code in <code>tests/test_logging.py</code> <pre><code>def test_assert_log_contains(self, caplog):\n    \"\"\"\n    This test demonstrates a helper function to assert that a specific log message is captured.\n    \"\"\"\n    with caplog.at_level(logging.INFO):\n        custom_log_function()\n\n    check_log_contains(caplog, logging.INFO, \"This is a custom log message\")\n</code></pre>"},{"location":"markers.html","title":"Markers","text":""},{"location":"markers.html#tests.test_markers.TestMarkers","title":"<code>tests.test_markers.TestMarkers</code>","text":"<p>This class demonstrates the usage of various markers in pytest.</p> <p>Custom Markers: Custom markers allow you to categorize tests for different purposes.</p> <p>To define custom markers, you should register them in a pyproject.toml file. Create a pyproject.toml file in your project root with the following content:</p> <p>[tool.pytest.ini_options] markers = [     \"slow: marks tests as slow (deselect with '-m \"not slow\"')\",     \"fast: marks tests as fast\",     \"regression: marks tests for regression testing\" ]</p> <p>Usage: - Run tests marked as slow:   pytest -m slow - Run tests excluding the slow ones:   pytest -m \"not slow\" - Run tests marked for regression:   pytest -m regression</p>"},{"location":"markers.html#tests.test_markers.TestMarkers.test_skip_example","title":"<code>test_skip_example()</code>","text":"<p>This test is skipped and will not be run.</p>          Source code in <code>tests/test_markers.py</code> <pre><code>@pytest.mark.skip(reason=\"Skipping this test for demonstration purposes\")\ndef test_skip_example(self):\n    \"\"\"\n    This test is skipped and will not be run.\n    \"\"\"\n    assert 1 == 1\n</code></pre>"},{"location":"markers.html#tests.test_markers.TestMarkers.test_conditional_skip","title":"<code>test_conditional_skip()</code>","text":"<p>This test is conditionally skipped based on some condition.</p>          Source code in <code>tests/test_markers.py</code> <pre><code>@pytest.mark.skipif(True, reason=\"This test is conditionally skipped\")\ndef test_conditional_skip(self):\n    \"\"\"\n    This test is conditionally skipped based on some condition.\n    \"\"\"\n    assert True\n</code></pre>"},{"location":"markers.html#tests.test_markers.TestMarkers.test_expected_fail","title":"<code>test_expected_fail()</code>","text":"<p>This test is expected to fail.</p>          Source code in <code>tests/test_markers.py</code> <pre><code>@pytest.mark.xfail(reason=\"This test is expected to fail\")\ndef test_expected_fail(self):\n    \"\"\"\n    This test is expected to fail.\n    \"\"\"\n    assert 1 == 2\n</code></pre>"},{"location":"markers.html#tests.test_markers.TestMarkers.test_parametrized","title":"<code>test_parametrized(input_data, expected)</code>","text":"<p>This test uses the parametrize marker to test multiple inputs.</p> <p>You can read more about parametrized tests in the parametrization section.</p>          Source code in <code>tests/test_markers.py</code> <pre><code>@pytest.mark.parametrize(\n    \"input_data, expected\",\n    [\n        (1, 2),\n        (2, 3),\n        (3, 4),\n    ],\n)\ndef test_parametrized(self, input_data, expected):\n    \"\"\"\n    This test uses the parametrize marker to test multiple inputs.\n\n    You can read more about parametrized tests in the\n    [parametrization](parametrization.md#TestParametrization) section.\n    \"\"\"\n    assert input_data + 1 == expected\n</code></pre>"},{"location":"mocking.html","title":"Mocking","text":""},{"location":"mocking.html#tests.test_mocking.TestMockingVariables","title":"<code>tests.test_mocking.TestMockingVariables</code>","text":"<p>Mocking is a technique used in unit testing to replace real objects with mock objects. This is useful when you want to isolate the code being tested from external dependencies.</p>"},{"location":"mocking.html#tests.test_mocking.TestMockingVariables.test_mock_variable_unittest","title":"<code>test_mock_variable_unittest()</code>","text":"<p>This test demonstrates mocking a variable with Pythons built-in unittest.mock library.</p>          Source code in <code>tests/test_mocking.py</code> <pre><code>def test_mock_variable_unittest(self):\n    \"\"\"\n    This test demonstrates mocking a variable with Pythons\n    built-in unittest.mock library.\n    \"\"\"\n    with mock.patch(\"tests.test_mocking.VARIABLE\", \"mocked_value\"):\n        assert VARIABLE == \"mocked_value\"\n</code></pre>"},{"location":"mocking.html#tests.test_mocking.TestMockingVariables.test_mock_variable_pytest","title":"<code>test_mock_variable_pytest(mocker)</code>","text":"<p>This test demonstrates mocking a variable using the pytest-mock library.</p>          Source code in <code>tests/test_mocking.py</code> <pre><code>def test_mock_variable_pytest(self, mocker):\n    \"\"\"\n    This test demonstrates mocking a variable using the pytest-mock library.\n    \"\"\"\n    mocker.patch(\"tests.test_mocking.VARIABLE\", \"mocked_value\")\n    assert VARIABLE == \"mocked_value\"\n</code></pre>"},{"location":"mocking.html#tests.test_mocking.TestMockingFunctions","title":"<code>tests.test_mocking.TestMockingFunctions</code>","text":"<p>This class demonstrates how to mock functions.</p>"},{"location":"mocking.html#tests.test_mocking.TestMockingFunctions.test_mock_function_unittest","title":"<code>test_mock_function_unittest()</code>","text":"<p>This test demonstrates mocking a function with Pythons built-in unittest.mock library.</p>          Source code in <code>tests/test_mocking.py</code> <pre><code>def test_mock_function_unittest(self):\n    \"\"\"\n    This test demonstrates mocking a function with Pythons\n    built-in unittest.mock library.\n    \"\"\"\n\n    def mock_function():\n        return \"mocked result\"\n\n    with mock.patch(\"tests.test_mocking.function_to_mock\", mock_function):\n        assert function_to_mock() == \"mocked result\"\n</code></pre>"},{"location":"mocking.html#tests.test_mocking.TestMockingFunctions.test_mock_function_unittest_assert_called_with","title":"<code>test_mock_function_unittest_assert_called_with()</code>","text":"<p>This test demonstrates how to assert that a mocked function was called with specific arguments.</p> <p>Note that we do not use a separate function here. Because then we would have replaced the mocked function with our function, which do not have the assert_called_with method.</p>          Source code in <code>tests/test_mocking.py</code> <pre><code>def test_mock_function_unittest_assert_called_with(self):\n    \"\"\"\n    This test demonstrates how to assert that a mocked function\n    was called with specific arguments.\n\n    Note that we do not use a separate function here. Because then we would have\n    replaced the mocked function with our function, which do not have the\n    assert_called_with method.\n    \"\"\"\n\n    with mock.patch(\"tests.test_mocking.function_to_mock\") as mocked_function:\n        function_to_mock(\"mocked result\")\n        mocked_function.assert_called_with(\"mocked result\")\n</code></pre>"},{"location":"mocking.html#tests.test_mocking.TestMockingFunctions.test_mock_function_pytest","title":"<code>test_mock_function_pytest(mocker)</code>","text":"<p>This test demonstrates mocking a function using the pytest-mock library.</p> <p>Note that this do not use a context manager like the unittest.mock library.</p>          Source code in <code>tests/test_mocking.py</code> <pre><code>def test_mock_function_pytest(self, mocker):\n    \"\"\"\n    This test demonstrates mocking a function using the pytest-mock library.\n\n    Note that this do not use a context manager like the unittest.mock library.\n    \"\"\"\n    mocker.patch(\n        \"tests.test_mocking.function_to_mock\", return_value=\"mocked result\"\n    )\n    assert function_to_mock() == \"mocked result\"\n</code></pre>"},{"location":"mocking.html#tests.test_mocking.TestMockingFunctions.test_mock_function_pytest_assert_called_with","title":"<code>test_mock_function_pytest_assert_called_with(mocker)</code>","text":"<p>This test demonstrates how to assert that a mocked function was called with specific arguments using the pytest-mock library.</p> <p>Note that this do not use a context manager like the unittest.mock library.</p>          Source code in <code>tests/test_mocking.py</code> <pre><code>def test_mock_function_pytest_assert_called_with(self, mocker):\n    \"\"\"\n    This test demonstrates how to assert that a mocked function\n    was called with specific arguments using the pytest-mock library.\n\n    Note that this do not use a context manager like the unittest.mock library.\n    \"\"\"\n    mocked_function = mocker.patch(\"tests.test_mocking.function_to_mock\")\n    function_to_mock(\"mocked result\")\n    mocked_function.assert_called_with(\"mocked result\")\n</code></pre>"},{"location":"mocking.html#tests.test_mocking.TestMockingClasses","title":"<code>tests.test_mocking.TestMockingClasses</code>","text":"<p>This class demonstrates how to mock classes, methods, and class variables.</p>"},{"location":"mocking.html#tests.test_mocking.TestMockingClasses.test_mock_class_variable_unittest","title":"<code>test_mock_class_variable_unittest()</code>","text":"<p>This test demonstrates mocking a class variable using the unittest.mock library.</p>          Source code in <code>tests/test_mocking.py</code> <pre><code>def test_mock_class_variable_unittest(self):\n    \"\"\"\n    This test demonstrates mocking a class variable using the\n    unittest.mock library.\n    \"\"\"\n\n    class MockClass:\n        variable = \"mocked variable\"\n\n    with mock.patch(\"tests.test_mocking.ClassToMock\", MockClass):\n        instance = ClassToMock()\n        assert instance.variable == \"mocked variable\"\n</code></pre>"},{"location":"mocking.html#tests.test_mocking.TestMockingClasses.test_mock_class_variable_pytest","title":"<code>test_mock_class_variable_pytest(mocker)</code>","text":"<p>This test demonstrates mocking a class variable using the pytest-mock library.</p>          Source code in <code>tests/test_mocking.py</code> <pre><code>def test_mock_class_variable_pytest(self, mocker):\n    \"\"\"\n    This test demonstrates mocking a class variable using the pytest-mock library.\n    \"\"\"\n    mocker.patch(\"tests.test_mocking.ClassToMock.variable\", \"mocked variable\")\n    instance = ClassToMock()\n    assert instance.variable == \"mocked variable\"\n</code></pre>"},{"location":"mocking.html#tests.test_mocking.TestMockingClasses.test_mock_class_method_unittest","title":"<code>test_mock_class_method_unittest()</code>","text":"<p>This test demonstrates mocking a class method using the unittest.mock library.</p>          Source code in <code>tests/test_mocking.py</code> <pre><code>def test_mock_class_method_unittest(self):\n    \"\"\"\n    This test demonstrates mocking a class method using the\n    unittest.mock library.\n    \"\"\"\n\n    class MockClass:\n        def method(self):\n            return \"mocked method result\"\n\n    with mock.patch(\"tests.test_mocking.ClassToMock\", MockClass):\n        instance = ClassToMock()\n        assert instance.method() == \"mocked method result\"\n</code></pre>"},{"location":"mocking.html#tests.test_mocking.TestMockingClasses.test_mock_class_method_pytest","title":"<code>test_mock_class_method_pytest(mocker)</code>","text":"<p>This test demonstrates mocking a class method using the pytest-mock library.</p>          Source code in <code>tests/test_mocking.py</code> <pre><code>def test_mock_class_method_pytest(self, mocker):\n    \"\"\"\n    This test demonstrates mocking a class method using the pytest-mock library.\n    \"\"\"\n    mocker.patch(\n        \"tests.test_mocking.ClassToMock.method\", return_value=\"mocked method result\"\n    )\n    instance = ClassToMock()\n    assert instance.method() == \"mocked method result\"\n</code></pre>"},{"location":"mocking.html#tests.test_mocking.TestMockingFilesAndDirectories","title":"<code>tests.test_mocking.TestMockingFilesAndDirectories</code>","text":""},{"location":"mocking.html#tests.test_mocking.TestMockingFilesAndDirectories.test_mock_file_unittest","title":"<code>test_mock_file_unittest()</code>","text":"<p>This test demonstrates mocking file input using the unittest.mock library.</p>          Source code in <code>tests/test_mocking.py</code> <pre><code>def test_mock_file_unittest(self):\n    \"\"\"\n    This test demonstrates mocking file input using the unittest.mock library.\n    \"\"\"\n    mock_open = mock.mock_open(read_data=\"mocked file content\")\n    with mock.patch(\"builtins.open\", mock_open):\n        with open(\"dummy_file.txt\") as f:\n            assert f.read() == \"mocked file content\"\n</code></pre>"},{"location":"mocking.html#tests.test_mocking.TestMockingFilesAndDirectories.test_mock_file_pytest","title":"<code>test_mock_file_pytest(mocker)</code>","text":"<p>This test demonstrates mocking file input using the pytest-mock library.</p>          Source code in <code>tests/test_mocking.py</code> <pre><code>def test_mock_file_pytest(self, mocker):\n    \"\"\"\n    This test demonstrates mocking file input using the pytest-mock library.\n    \"\"\"\n    mock_open = mocker.mock_open(read_data=\"mocked file content\")\n    mocker.patch(\"builtins.open\", mock_open)\n\n    with open(\"dummy_file.txt\") as f:\n        assert f.read() == \"mocked file content\"\n</code></pre>"},{"location":"mocking.html#tests.test_mocking.TestMockingFilesAndDirectories.test_mock_directory_unittest","title":"<code>test_mock_directory_unittest()</code>","text":"<p>This test demonstrates mocking directory structure with files using the unittest.mock library.</p>          Source code in <code>tests/test_mocking.py</code> <pre><code>def test_mock_directory_unittest(self):\n    \"\"\"\n    This test demonstrates mocking directory structure with files\n    using the unittest.mock library.\n    \"\"\"\n    with TemporaryDirectory() as d:\n        with mock.patch(\"os.listdir\", return_value=[\"file1.txt\", \"file2.txt\"]):\n            assert sorted(os.listdir(d)) == [\"file1.txt\", \"file2.txt\"]\n</code></pre>"},{"location":"mocking.html#tests.test_mocking.TestMockingFilesAndDirectories.test_mock_directory_pytest","title":"<code>test_mock_directory_pytest(tmp_path)</code>","text":"<p>This test demonstrates mocking directory structure with files using the tmp_path fixture from pytest.</p>          Source code in <code>tests/test_mocking.py</code> <pre><code>def test_mock_directory_pytest(self, tmp_path):\n    \"\"\"\n    This test demonstrates mocking directory structure with files\n    using the tmp_path fixture from pytest.\n    \"\"\"\n    d = tmp_path / \"dummy_directory\"\n    d.mkdir()\n    (d / \"file1.txt\").write_text(\"content1\")\n    (d / \"file2.txt\").write_text(\"content2\")\n    with mock.patch(\n        \"os.listdir\", return_value=sorted([p.name for p in d.iterdir()])\n    ):\n        assert sorted(os.listdir(d)) == [\"file1.txt\", \"file2.txt\"]\n</code></pre>"},{"location":"mocking.html#tests.test_mocking.TestMockingEnvironmentVariables","title":"<code>tests.test_mocking.TestMockingEnvironmentVariables</code>","text":"<p>This class demonstrates how to mock environment variables.</p>"},{"location":"mocking.html#tests.test_mocking.TestMockingEnvironmentVariables.test_mock_environment_variable_unittest","title":"<code>test_mock_environment_variable_unittest()</code>","text":"<p>This test demonstrates mocking an environment variable using the unittest.mock library.</p>          Source code in <code>tests/test_mocking.py</code> <pre><code>def test_mock_environment_variable_unittest(self):\n    \"\"\"\n    This test demonstrates mocking an environment variable using the\n    unittest.mock library.\n    \"\"\"\n    with mock.patch.dict(os.environ, {\"ENV_VAR\": \"mocked_value\"}):\n        assert os.environ[\"ENV_VAR\"] == \"mocked_value\"\n</code></pre>"},{"location":"mocking.html#tests.test_mocking.TestMockingEnvironmentVariables.test_mock_environment_variable_pytest","title":"<code>test_mock_environment_variable_pytest(mocker)</code>","text":"<p>This test demonstrates mocking an environment variable using the pytest-mock library.</p>          Source code in <code>tests/test_mocking.py</code> <pre><code>def test_mock_environment_variable_pytest(self, mocker):\n    \"\"\"\n    This test demonstrates mocking an environment variable using the pytest-mock library.\n    \"\"\"\n    mocker.patch.dict(os.environ, {\"ENV_VAR\": \"mocked_value\"})\n    assert os.environ[\"ENV_VAR\"] == \"mocked_value\"\n</code></pre>"},{"location":"mocking.html#tests.test_mocking.TestMockingApi","title":"<code>tests.test_mocking.TestMockingApi</code>","text":"<p>This class demonstrates how to mock API responses.</p>"},{"location":"mocking.html#tests.test_mocking.TestMockingApi.test_mock_api_response_unittest","title":"<code>test_mock_api_response_unittest()</code>","text":"<p>This test demonstrates mocking an API response.</p>          Source code in <code>tests/test_mocking.py</code> <pre><code>def test_mock_api_response_unittest(self):\n    \"\"\"\n    This test demonstrates mocking an API response.\n    \"\"\"\n    mock_response = mock.Mock()\n    mock_response.status_code = 200\n    mock_response.json.return_value = {\"key\": \"value\"}\n    with mock.patch(\"requests.get\", return_value=mock_response):\n        response = requests.get(\"https://api.example.com/data\")\n        assert response.status_code == 200\n        assert response.json() == {\"key\": \"value\"}\n</code></pre>"},{"location":"mocking.html#tests.test_mocking.TestMockingApi.test_mock_api_response_pytest","title":"<code>test_mock_api_response_pytest(mocker)</code>","text":"<p>This test demonstrates mocking an API response using the pytest-mock library.</p>          Source code in <code>tests/test_mocking.py</code> <pre><code>def test_mock_api_response_pytest(self, mocker):\n    \"\"\"\n    This test demonstrates mocking an API response using the pytest-mock library.\n    \"\"\"\n    mock_response = mocker.Mock()\n    mock_response.status_code = 200\n    mock_response.json.return_value = {\"key\": \"value\"}\n    mocker.patch(\"requests.get\", return_value=mock_response)\n    response = requests.get(\"https://api.example.com/data\")\n    assert response.status_code == 200\n    assert response.json() == {\"key\": \"value\"}\n</code></pre>"},{"location":"package-specific-test-libraries.html","title":"Package-Specific Test Libraries","text":""},{"location":"package-specific-test-libraries.html#introduction","title":"Introduction","text":"<p>Note</p> <p>Before starting to write tests, always check if there is a package-specific test library available for the package you are testing.</p> <p>When writing tests, it is common to use a test library that is specific to the package that is being tested. This is because the test library is often tailored to the package and can provide additional functionality that is not available in the standard test libraries.</p> <p>The following sections cover some examples of how to use package-specific test libraries in Python.</p>"},{"location":"package-specific-test-libraries.html#fastapi","title":"FastAPI","text":"<p>FastAPI is a modern web framework for building APIs with Python 3.6+ based on standard Python type hints. It is designed to be easy to use and fast to develop with.</p>"},{"location":"package-specific-test-libraries.html#testing-fastapi-endpoints","title":"Testing FastAPI endpoints","text":"<p>FastAPI provides a test client that can be used to test your API endpoints. The test client is a Pydantic model that can be used to make requests to your API and assert the responses.</p> <p>Here is an example of how to use the test client to test a FastAPI endpoint given the following code:</p> <pre><code># main.py\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/\")\nasync def read_root():\n    return {\"message\": \"Hello World\"}\n</code></pre> <p>You can test the endpoint using the following code:</p> <pre><code># test_main.py\nfrom fastapi.testclient import TestClient\nfrom main import app\n\nclient = TestClient(app)\n\ndef test_read_root():\n    response = client.get(\"/\")\n    assert response.status_code == 200\n    assert response.json() == {\"message\": \"Hello World\"}\n</code></pre> <p>Here, the <code>TestClient</code> is used to simulate requests to the FastAPI application. This allows you to write tests that interact with your endpoints as if they were being called in a live environment.</p>"},{"location":"package-specific-test-libraries.html#requestsresponses","title":"Requests/Responses","text":"<p>You can use the responses library to mock HTTP responses from the requests library.</p>"},{"location":"package-specific-test-libraries.html#testing-http-requests","title":"Testing HTTP requests","text":"<p>Here is an example of how to use the responses library to mock an HTTP response given the following code:</p> <pre><code># code.py\nimport requests\n\ndef get_data(url):\n    response = requests.get(url)\n    return response.json()\n</code></pre> <p>You can test the <code>get_data</code> function using the following code:</p> <pre><code># test_code.py\nimport responses\nimport requests\nfrom code import get_data\n\n@responses.activate\ndef test_get_data():\n    url = \"https://api.example.com/data\"\n    responses.add(responses.GET, url, json={\"key\": \"value\"}, status=200)\n\n    response = get_data(url)\n    assert response == {\"key\": \"value\"}\n    assert len(responses.calls) == 1\n    assert responses.calls[0].request.url == url\n    assert responses.calls[0].response.status_code == 200\n</code></pre> <p>The <code>responses</code> library is used to mock the HTTP response from the <code>requests</code> library. This allows you to test the <code>get_data</code> function without making actual HTTP requests.</p> <p>Tip</p> <p>The <code>responses</code> library is not specific to requests and can be used with other HTTP libraries as well.</p>"},{"location":"package-specific-test-libraries.html#click","title":"Click","text":"<p>Click is a Python package for creating command-line interfaces. It is designed to be easy to use and to provide a consistent interface for building command-line applications.</p>"},{"location":"package-specific-test-libraries.html#testing-click-commands","title":"Testing Click commands","text":"<p>Click provides a test runner that can be used to test Click commands. The test runner is a context manager that can be used to run Click commands and assert the output.</p> <p>Here is an example of how to use the test runner to test a Click command given the following code:</p> <pre><code># code.py\nimport click\n\n@click.command()\n@click.option(\"--name\", default=\"World\", help=\"The name to greet.\")\ndef greet(name):\n    click.echo(f\"Hello, {name}!\")\n\nif __name__ == \"__main__\":\n    greet()\n</code></pre> <p>You can test the <code>greet</code> command using the following code:</p> <pre><code># test_code.py\nfrom click.testing import CliRunner\nfrom code import greet\n\ndef test_greet():\n    runner = CliRunner()\n    result = runner.invoke(greet, [\"--name\", \"Alice\"])\n    assert result.exit_code == 0\n    assert result.output == \"Hello, Alice!\\n\"\n</code></pre> <p>Here, the <code>CliRunner</code> is used to simulate running the <code>greet</code> command. This allows you to write tests that interact with your Click commands as if they were being run in a live environment.</p>"},{"location":"package-specific-test-libraries.html#conclusion","title":"Conclusion","text":"<p>Using package-specific test libraries can make writing tests easier and more efficient. By leveraging the functionality provided by these libraries, you can write tests that are more robust and maintainable.</p> <p>When writing tests for a package, always check if there is a package-specific test library available. This can save you time and effort and help you write tests that are tailored to the package you are testing.</p>"},{"location":"parametrization.html","title":"Parametrization","text":""},{"location":"parametrization.html#tests.test_parametrization.TestParametrization","title":"<code>tests.test_parametrization.TestParametrization</code>","text":"<p>This class demonstrates the usage of parameterized tests in pytest. Parameterized tests allow you to define multiple sets of arguments for a single test function.</p>"},{"location":"parametrization.html#tests.test_parametrization.TestParametrization.test_add_one","title":"<code>test_add_one(input_data, expected)</code>","text":"<p>This test checks if adding 1 to the input_data produces the expected result.</p>          Source code in <code>tests/test_parametrization.py</code> <pre><code>@pytest.mark.parametrize(\n    \"input_data, expected\",\n    [\n        (1, 2),\n        (2, 3),\n        (3, 4),\n    ],\n)\ndef test_add_one(self, input_data, expected):\n    \"\"\"\n    This test checks if adding 1 to the input_data produces the expected result.\n    \"\"\"\n    assert input_data + 1 == expected\n</code></pre>"},{"location":"parametrization.html#tests.test_parametrization.TestParametrization.test_string_contains","title":"<code>test_string_contains(string, substring, expected)</code>","text":"<p>This test checks if a substring is present in the main string.</p>          Source code in <code>tests/test_parametrization.py</code> <pre><code>@pytest.mark.parametrize(\n    \"string, substring, expected\",\n    [\n        (\"Hello, world!\", \"world\", True),\n        (\"Hello, world!\", \"Python\", False),\n        (\"Pytest is great\", \"great\", True),\n    ],\n)\ndef test_string_contains(self, string, substring, expected):\n    \"\"\"\n    This test checks if a substring is present in the main string.\n    \"\"\"\n    assert (substring in string) == expected\n</code></pre>"},{"location":"parametrization.html#tests.test_parametrization.TestParametrization.test_list_equality","title":"<code>test_list_equality(list1, list2, expected)</code>","text":"<p>This test checks if two lists are equal.</p>          Source code in <code>tests/test_parametrization.py</code> <pre><code>@pytest.mark.parametrize(\n    \"list1, list2, expected\",\n    [\n        ([1, 2, 3], [1, 2, 3], True),\n        ([1, 2], [2, 1], False),\n        ([], [], True),\n    ],\n)\ndef test_list_equality(self, list1, list2, expected):\n    \"\"\"\n    This test checks if two lists are equal.\n    \"\"\"\n    assert (list1 == list2) == expected\n</code></pre>"},{"location":"parametrization.html#tests.test_parametrization.TestParametrization.test_division","title":"<code>test_division(dividend, divisor, expected)</code>","text":"<p>This test checks if division produces the expected result.</p>          Source code in <code>tests/test_parametrization.py</code> <pre><code>@pytest.mark.parametrize(\n    \"dividend, divisor, expected\",\n    [\n        (10, 2, 5),\n        (9, 3, 3),\n        (5, 2, 2.5),\n    ],\n)\ndef test_division(self, dividend, divisor, expected):\n    \"\"\"\n    This test checks if division produces the expected result.\n    \"\"\"\n    assert dividend / divisor == expected\n</code></pre>"},{"location":"parametrization.html#tests.test_parametrization.TestParametrization.test_power","title":"<code>test_power(base, exponent, expected)</code>","text":"<p>This test checks if raising a base to an exponent gives the expected result.</p>          Source code in <code>tests/test_parametrization.py</code> <pre><code>@pytest.mark.parametrize(\n    \"base, exponent, expected\",\n    [\n        (2, 3, 8),\n        (3, 2, 9),\n        (5, 0, 1),\n    ],\n)\ndef test_power(self, base, exponent, expected):\n    \"\"\"\n    This test checks if raising a base to an exponent gives the expected result.\n    \"\"\"\n    assert base**exponent == expected\n</code></pre>"},{"location":"parametrization.html#tests.test_parametrization.TestParametrization.test_dict_values","title":"<code>test_dict_values(person, request_param, expected_value)</code>","text":"<p>This test checks if the dictionary returns the expected value for a given key.</p>          Source code in <code>tests/test_parametrization.py</code> <pre><code>@pytest.mark.parametrize(\n    \"person, request_param, expected_value\",\n    [\n        ({\"name\": \"Alice\", \"age\": 30}, \"name\", \"Alice\"),\n        ({\"name\": \"Bob\", \"age\": 25}, \"age\", 25),\n        ({\"name\": \"Charlie\", \"age\": 35}, \"name\", \"Charlie\"),\n    ],\n)\ndef test_dict_values(self, person, request_param, expected_value):\n    \"\"\"\n    This test checks if the dictionary returns the expected value for a given key.\n    \"\"\"\n    assert person[request_param] == expected_value\n</code></pre>"},{"location":"parametrization.html#tests.test_parametrization.TestParametrization.test_sum_of_list","title":"<code>test_sum_of_list(integer_list, target_sum, expected)</code>","text":"<p>This test checks if the sum of the list equals the target sum.</p>          Source code in <code>tests/test_parametrization.py</code> <pre><code>@pytest.mark.parametrize(\n    \"integer_list, target_sum, expected\",\n    [\n        ([1, 2, 3], 6, True),\n        ([1, 2, 3], 7, False),\n        ([1, 1, 1], 3, True),\n    ],\n)\ndef test_sum_of_list(self, integer_list, target_sum, expected):\n    \"\"\"\n    This test checks if the sum of the list equals the target sum.\n    \"\"\"\n    assert (sum(integer_list) == target_sum) == expected\n</code></pre>"},{"location":"pytest-cli.html","title":"Pytest CLI Tips","text":"<p><code>pytest</code> provides a versatile and powerful command-line interface (CLI) with numerous options that can help tailor test execution to your needs. This guide covers some of the most useful <code>pytest</code> CLI options, including filtering tests, capturing output, running tests in parallel, and more.</p>"},{"location":"pytest-cli.html#filtering-tests","title":"Filtering Tests","text":""},{"location":"pytest-cli.html#-k-run-tests-matching-specific-expressions","title":"<code>-k</code>: Run Tests Matching Specific Expressions","text":"<p>Use the <code>-k</code> option to run tests that match a given expression. This is useful when you want to run a subset of tests based on their names or any substring.</p> <pre><code>pytest -k \"expression\"\n</code></pre> <p>Examples:</p> <ul> <li>Run tests with \"data\" in their name:</li> </ul> <pre><code>pytest -k \"data\"\n</code></pre> <ul> <li>Run tests that have <code>test_create</code> in their name:</li> </ul> <pre><code>pytest -k \"test_create\"\n</code></pre> <p>You can also use logical expressions:</p> <pre><code>pytest -k \"test_method or test_function\"\n</code></pre> <p>or</p> <pre><code>pytest -k \"test_method and not test_function\"\n</code></pre>"},{"location":"pytest-cli.html#capturing-output","title":"Capturing Output","text":""},{"location":"pytest-cli.html#-s-disable-output-capturing","title":"<code>-s</code>: Disable Output Capturing","text":"<p>By default, <code>pytest</code> captures all output (e.g., print statements) during test execution. Use the <code>-s</code> option to disable this behavior and allow output to be displayed in real-time.</p> <pre><code>pytest -s\n</code></pre>"},{"location":"pytest-cli.html#parallel-execution","title":"Parallel Execution","text":""},{"location":"pytest-cli.html#pytest-xdist-run-tests-in-parallel","title":"<code>pytest-xdist</code>: Run Tests in Parallel","text":"<p><code>pytest-xdist</code> is a plugin that allows you to run tests in parallel using multiple CPU cores.</p>"},{"location":"pytest-cli.html#installation","title":"Installation","text":"<pre><code>pip install pytest-xdist\n</code></pre>"},{"location":"pytest-cli.html#usage","title":"Usage","text":"<p>Use the <code>-n</code> option to specify the number of CPU cores to use for parallel test execution:</p> <pre><code>pytest -n 4\n</code></pre> <p>This will distribute the tests across 4 CPU cores, running them concurrently and thus reducing the overall testing time.</p>"},{"location":"pytest-cli.html#markers","title":"Markers","text":""},{"location":"pytest-cli.html#-m-run-tests-with-specific-markers","title":"<code>-m</code>: Run Tests with Specific Markers","text":"<p>Use the <code>-m</code> option to run tests that are marked with a specific keyword or marker.</p> <pre><code>pytest -m \"marker\"\n</code></pre> <p>Examples:</p> <ul> <li>Run tests marked with <code>slow</code>:</li> </ul> <pre><code>pytest -m \"slow\"\n</code></pre> <ul> <li>Run tests excluding <code>slow</code> marked tests:</li> </ul> <pre><code>pytest -m \"not slow\"\n</code></pre>"},{"location":"pytest-cli.html#fail-fast","title":"Fail Fast","text":""},{"location":"pytest-cli.html#-x-stop-after-first-failure","title":"<code>-x</code>: Stop After First Failure","text":"<p>Use the <code>-x</code> option to stop test execution immediately after the first failure.</p> <pre><code>pytest -x\n</code></pre>"},{"location":"pytest-cli.html#-maxfail-specify-number-of-failures-before-stopping","title":"<code>--maxfail</code>: Specify Number of Failures Before Stopping","text":"<p>Use the <code>--maxfail</code> option to specify the maximum number of failures allowed before stopping the test run.</p> <pre><code>pytest --maxfail=3\n</code></pre>"},{"location":"pytest-cli.html#disabling-warnings","title":"Disabling Warnings","text":""},{"location":"pytest-cli.html#-p-nowarnings-disable-warnings","title":"<code>-p no:warnings</code>: Disable Warnings","text":"<p>Use the <code>-p no:warnings</code> option to disable warnings during test execution.</p> <pre><code>pytest -p no:warnings\n</code></pre>"},{"location":"pytest-cli.html#running-specific-tests","title":"Running Specific Tests","text":""},{"location":"pytest-cli.html#running-specific-test-files-or-directories","title":"Running Specific Test Files or Directories","text":"<p>You can specify particular test files or directories to run:</p> <pre><code>pytest tests/test_file.py\npytest tests/test_directory/\n</code></pre>"},{"location":"pytest-cli.html#running-specific-test-classes-or-functions","title":"Running Specific Test Classes or Functions","text":"<p>You can also run specific test classes or test functions within files:</p> <pre><code>pytest tests/test_file.py::TestClass\npytest tests/test_file.py::TestClass::test_function\n</code></pre>"},{"location":"pytest-cli.html#conclusion","title":"Conclusion","text":"<p>These <code>pytest</code> CLI options and plugins can greatly enhance your testing experience by providing fine-grained control over test selection, output capturing, parallel execution, and more. By leveraging these tools, you can optimize your testing workflow and improve efficiency.</p>"},{"location":"pytest-plugins.html","title":"Useful <code>pytest</code> Plugins","text":"<p><code>pytest</code> is a powerful testing framework for Python that can be extended with plugins to provide additional functionality, improve usability, and integrate with other tools. Below are some of the most useful <code>pytest</code> plugins that can help streamline and enhance your testing process.</p> <p>Note</p> <p>There is an absolute ton of plugins available for <code>pytest</code>. The ones listed here are just a few examples of the most commonly used plugins. For a more comprehensive list, check out the official <code>pytest</code> plugin list.</p>"},{"location":"pytest-plugins.html#pytest-cov","title":"pytest-cov","text":"<p><code>pytest-cov</code> is a <code>pytest</code> plugin that measures test coverage using <code>coverage.py</code>.</p>"},{"location":"pytest-plugins.html#installation","title":"Installation","text":"<pre><code>pip install pytest-cov\n</code></pre>"},{"location":"pytest-plugins.html#usage","title":"Usage","text":"<p>Simply run <code>pytest</code> with the <code>--cov</code> option:</p> <pre><code>pytest --cov=myproject\n</code></pre> <p>You can generate various types of reports by using different options:</p> <ul> <li>Text Report: <code>pytest --cov=myproject --cov-report=term</code></li> <li>HTML Report: <code>pytest --cov=myproject --cov-report=html</code></li> <li>XML Report: <code>pytest --cov=myproject --cov-report=xml</code></li> </ul>"},{"location":"pytest-plugins.html#pytest-mock","title":"pytest-mock","text":"<p><code>pytest-mock</code> is a <code>pytest</code> plugin that provides a convenient way to use the <code>mock</code> library in your tests.</p>"},{"location":"pytest-plugins.html#installation_1","title":"Installation","text":"<pre><code>pip install pytest-mock\n</code></pre>"},{"location":"pytest-plugins.html#usage_1","title":"Usage","text":"<p>Use the <code>mocker</code> fixture to create mocks in your tests:</p> <pre><code>def test_some_function(mocker):\n    mock_some_function = mocker.patch('myproject.module.some_function', return_value=42)\n    result = myproject.module.some_function()\n    assert result == 42\n</code></pre>"},{"location":"pytest-plugins.html#pytest-sugar","title":"pytest-sugar","text":"<p><code>pytest-sugar</code> is a plugin for <code>pytest</code> that changes the default look and feel of <code>pytest</code> to make it more visually appealing and informative.</p>"},{"location":"pytest-plugins.html#installation_2","title":"Installation","text":"<pre><code>pip install pytest-sugar\n</code></pre>"},{"location":"pytest-plugins.html#usage_2","title":"Usage","text":"<p>Simply run <code>pytest</code> as usual, and it will use <code>pytest-sugar</code> to display test results in a more readable format.</p> <pre><code>pytest\n</code></pre>"},{"location":"pytest-plugins.html#pytest-xdist","title":"pytest-xdist","text":"<p><code>pytest-xdist</code> is a <code>pytest</code> plugin that allows you to distribute your tests across multiple CPUs and run them in parallel.</p>"},{"location":"pytest-plugins.html#installation_3","title":"Installation","text":"<pre><code>pip install pytest-xdist\n</code></pre>"},{"location":"pytest-plugins.html#usage_3","title":"Usage","text":"<p>Use the <code>-n</code> option to specify the number of CPU cores to use:</p> <pre><code>pytest -n 4\n</code></pre>"},{"location":"pytest-plugins.html#pytest-randomly","title":"pytest-randomly","text":"<p><code>pytest-randomly</code> is a plugin that randomizes the order of your tests to ensure they do not depend on each other.</p>"},{"location":"pytest-plugins.html#installation_4","title":"Installation","text":"<pre><code>pip install pytest-randomly\n</code></pre>"},{"location":"pytest-plugins.html#usage_4","title":"Usage","text":"<p>Simply run <code>pytest</code> as usual, and it will randomize the order of the tests.</p> <pre><code>pytest\n</code></pre>"},{"location":"pytest-plugins.html#pytest-django","title":"pytest-django","text":"<p><code>pytest-django</code> is a <code>pytest</code> plugin that provides a set of useful tools for testing Django applications.</p>"},{"location":"pytest-plugins.html#installation_5","title":"Installation","text":"<pre><code>pip install pytest-django\n</code></pre>"},{"location":"pytest-plugins.html#usage_5","title":"Usage","text":"<p>Create a <code>pytest.ini</code> file in your project root and configure it for Django:</p> <pre><code>[pytest]\nDJANGO_SETTINGS_MODULE = myproject.settings\n</code></pre> <p>Run <code>pytest</code> as usual, and it will use the Django configuration:</p> <pre><code>pytest\n</code></pre>"},{"location":"pytest-plugins.html#pytest-asyncio","title":"pytest-asyncio","text":"<p><code>pytest-asyncio</code> is a <code>pytest</code> plugin that provides support for testing asynchronous code.</p>"},{"location":"pytest-plugins.html#installation_6","title":"Installation","text":"<pre><code>pip install pytest-asyncio\n</code></pre>"},{"location":"pytest-plugins.html#usage_6","title":"Usage","text":"<p>Use the <code>@pytest.mark.asyncio</code> decorator to mark your asynchronous test functions:</p> <pre><code>import asyncio\nimport pytest\n\n@pytest.mark.asyncio\nasync def test_async_function():\n    result = await some_async_function()\n    assert result == 'expected result'\n</code></pre>"},{"location":"pytest-plugins.html#conclusion","title":"Conclusion","text":"<p>These <code>pytest</code> plugins enhance the functionality and usability of <code>pytest</code>, making it easier to measure code coverage, create mocks, run tests in parallel, and much more. By integrating these plugins into your testing workflow, you can improve the efficiency and effectiveness of your tests.</p>"},{"location":"test-structure-methodology.html","title":"Test structure methodology","text":"<p>This section will cover different methodologies for structuring tests. The goal is to make tests easier to read and understand, and to make it easier to write tests that are maintainable and scalable.</p>"},{"location":"test-structure-methodology.html#given-when-then","title":"Given, When, Then","text":"<p>The Given, When, Then (GWT) test structure is a way to organize tests in a way that makes them easier to read and understand. The structure is as follows:</p> <ol> <li>Given: Set up the initial state of the system under test (SUT).</li> <li>When: Perform the action that you want to test.</li> <li>Then: Check that the expected result has occurred.</li> </ol>"},{"location":"test-structure-methodology.html#example","title":"Example","text":"<pre><code>def test_addition():\n    # Given\n    x = 1\n    y = 2\n\n    # When\n    result = x + y\n\n    # Then\n    assert result == 3\n</code></pre>"},{"location":"test-structure-methodology.html#arrange-act-assert","title":"Arrange, Act, Assert","text":"<p>The Arrange, Act, Assert (AAA) test structure is another way to organize tests. The structure is as follows:</p> <ol> <li>Arrange: Set up the initial state of the system under test (SUT).</li> <li>Act: Perform the action that you want to test.</li> <li>Assert: Check that the expected result has occurred.</li> </ol>"},{"location":"test-structure-methodology.html#example_1","title":"Example","text":"<pre><code>def test_addition():\n    # Arrange\n    x = 1\n    y = 2\n\n    # Act\n    result = x + y\n\n    # Assert\n    assert result == 3\n</code></pre>"},{"location":"test-structure-methodology.html#conclusion","title":"Conclusion","text":"<p>Both the GWT and AAA test structures are useful ways to organize tests. The choice of which structure to use will depend on personal preference and the specific requirements of the test. The most important thing is to be consistent in a project and to make sure that tests are easy to read and understand.</p>"}]}